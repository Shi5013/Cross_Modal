{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir ../sample/\n",
      "['../sample/gt.txt', '../sample/test', '../sample/train', '../sample/val']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def filename_list(dir):\n",
    "    images = []\n",
    "    dir = os.path.expanduser(dir)# 扩展用户名。加上前面的部分\n",
    "    # print('dir {}'.format(dir))\n",
    "    for filename in os.listdir(dir):\n",
    "        # print(filename)\n",
    "        file_path = os.path.join(dir, filename)\n",
    "        images.append(file_path)\n",
    "        # print(file_path)\n",
    "    # print(images)\n",
    "    return images #这是返回了一个列表\n",
    "file_list = filename_list('../sample/')\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据的维度: (32, 96, 96)\n",
      "数据的大小（元素个数）: 294912\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. 读取 .npy 文件\n",
    "data = np.load('../sample/train/init1/MR_1.npy')  # 用实际文件名替代 'your_file.npy'\n",
    "\n",
    "# 2. 查看数据的维度\n",
    "print(\"数据的维度:\", data.shape)\n",
    "\n",
    "# 3. 查看数据的大小（元素个数）\n",
    "print(\"数据的大小（元素个数）:\", data.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输入大小: torch.Size([1, 8, 32, 32])\n",
      "上采样后的大小: torch.Size([1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设你的输入图像大小为 (batch_size, channels, height, width)\n",
    "input_size = (1, 8, 32, 32)  # 示例输入大小\n",
    "\n",
    "# 创建一个示例的输入\n",
    "x = torch.randn(input_size)\n",
    "\n",
    "# 使用Upsample来进行上采样，以便将图像大小恢复到原始尺寸\n",
    "upsample_factor = 2  # 上采样因子\n",
    "upsampled_x = nn.functional.interpolate(x, scale_factor=upsample_factor, mode='nearest')\n",
    "\n",
    "# 检查上采样后的张量大小\n",
    "print(\"原始输入大小:\", x.size())\n",
    "print(\"上采样后的大小:\", upsampled_x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输入大小: torch.Size([1, 8, 32, 32])\n",
      "上采样后的大小: torch.Size([1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设你的输入图像大小为 (batch_size, channels, height, width)\n",
    "input_size = (1, 8, 32, 32)  # 示例输入大小\n",
    "\n",
    "# 创建一个示例的输入\n",
    "x = torch.randn(input_size)\n",
    "\n",
    "# 反卷积层用于上采样以恢复原始图像大小\n",
    "# 在这个示例中，我们将上采样因子设置为2\n",
    "upsample_factor = 2\n",
    "\n",
    "# 创建一个反卷积层\n",
    "deconv_layer = nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=4, stride=upsample_factor, padding=1)\n",
    "\n",
    "# 上采样操作\n",
    "upsampled_x = deconv_layer(x)\n",
    "\n",
    "# 检查上采样后的张量大小\n",
    "print(\"原始输入大小:\", x.size())\n",
    "print(\"上采样后的大小:\", upsampled_x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输入大小: torch.Size([1, 64, 16, 16, 16])\n",
      "卷积后大小： torch.Size([1, 32, 18, 18, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设你的输入图像大小为 (batch_size, channels, depth, height, width)\n",
    "input_size = (1, 64, 16, 16, 16)  # 示例输入大小\n",
    "\n",
    "# 创建一个示例的输入\n",
    "x = torch.randn(input_size)\n",
    "\n",
    "# # 上采样因子（在深度、高度和宽度方向上的上采样倍数）\n",
    "# depth_upsample = 2\n",
    "# height_upsample = 2\n",
    "# width_upsample = 2\n",
    "\n",
    "# deconv_layer = nn.ConvTranspose3d(in_channels=64, out_channels=32, kernel_size=4, stride=4, padding=0)\n",
    "\n",
    "# upsampled_x = deconv_layer(x)\n",
    "\n",
    "# # 看一下池化\n",
    "# maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "# x = maxpool(upsampled_x)\n",
    "# 检查上采样后的张量大小\n",
    "\n",
    "conv = nn.Conv3d(in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=1,\n",
    "            stride=(1, 1, 1),\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "conv1 = conv(x)\n",
    "print(\"原始输入大小:\", x.size())\n",
    "print('卷积后大小：',conv1.size())\n",
    "# print(\"上采样后的大小:\", upsampled_x.size())\n",
    "# print('池化后大小：',x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8547, -0.1450],\n",
      "        [-0.1727,  0.0471]])\n",
      "===========\n",
      "tensor([[ 0.4295, -0.3780],\n",
      "        [ 1.6908, -1.1901]])\n",
      "===========\n",
      "tensor([[-0.4252, -0.5230],\n",
      "        [ 1.5182, -1.1431]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x1 = torch.randn((2,2))\n",
    "\n",
    "x2 = torch.randn((2,2))\n",
    "\n",
    "print(x1)\n",
    "print(\"===========\")\n",
    "print(x2)\n",
    "print(\"===========\")\n",
    "print(x1+x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 8, 32, 32])\n",
      "torch.Size([1, 32, 8, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NLBlockND_cross(nn.Module):\n",
    "    # Our implementation of the attention block referenced https://github.com/tea1528/Non-Local-NN-Pytorch\n",
    "    # 这一块儿就是夸模态注意力模块\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded',\n",
    "                 dimension=3, bn_layer=True):\n",
    "        \"\"\"Implementation of Non-Local Block with 4 different pairwise functions but doesn't include subsampling trick\n",
    "        args:\n",
    "            in_channels: original channel size (1024 in the paper)\n",
    "            inter_channels: channel size inside the block if not specifed reduced to half (512 in the paper)\n",
    "            mode: supports Gaussian, Embedded Gaussian, Dot Product, and Concatenation\n",
    "            dimension: can be 1 (temporal), 2 (spatial), 3 (spatiotemporal)\n",
    "            bn_layer: whether to add batch norm\n",
    "        \"\"\"\n",
    "        super(NLBlockND_cross, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "\n",
    "        if mode not in ['gaussian', 'embedded', 'dot', 'concatenate']:\n",
    "            raise ValueError('`mode` must be one of `gaussian`, `embedded`, `dot` or `concatenate`')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        # the channel size is reduced to half inside the block\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        # assign appropriate convolutional, max pool, and batch norm layers for different dimensions\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        # function g in the paper which goes through conv. with kernel size 1\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "\n",
    "        # add BatchNorm layer after the last conv layer\n",
    "        # 为非局部块的最后一个卷积层添加批量归一化，以提高模型的训练稳定性，并确保初始状态是一个恒等映射\n",
    "        if bn_layer:\n",
    "            self.W_z = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            # from section 4.1 of the paper, initializing params of BN ensures that the initial state of non-local block is identity mapping\n",
    "            nn.init.constant_(self.W_z[1].weight, 0)\n",
    "            nn.init.constant_(self.W_z[1].bias, 0)\n",
    "        else:\n",
    "            self.W_z = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1)\n",
    "\n",
    "            # from section 3.3 of the paper by initializing Wz to 0, this block can be inserted to any existing architecture\n",
    "            nn.init.constant_(self.W_z.weight, 0)\n",
    "            nn.init.constant_(self.W_z.bias, 0)\n",
    "\n",
    "        # define theta and phi for all operations except gaussian\n",
    "        if self.mode == \"embedded\" or self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "            self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "\n",
    "        if self.mode == \"concatenate\":\n",
    "            self.W_f = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.inter_channels * 2, out_channels=1, kernel_size=1),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x_thisBranch, x_otherBranch):\n",
    "        #x_thisBranch for g and theta\n",
    "        #x_otherBranch for phi\n",
    "        \"\"\"\n",
    "        args\n",
    "            x: (N, C, T, H, W) for dimension=3; (N, C, H, W) for dimension 2; (N, C, T) for dimension 1\n",
    "        \"\"\"\n",
    "        # print(x_thisBranch.shape)\n",
    "\n",
    "        batch_size = x_thisBranch.size(0)\n",
    "\n",
    "        # (N, C, THW)\n",
    "        # this reshaping and permutation is from the spacetime_nonlocal function in the original Caffe2 implementation\n",
    "        g_x = self.g(x_thisBranch).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        if self.mode == \"gaussian\":\n",
    "            theta_x = x_thisBranch.view(batch_size, self.in_channels, -1)\n",
    "            phi_x = x_otherBranch.view(batch_size, self.in_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == \"embedded\" or self.mode == \"dot\":\n",
    "            theta_x = self.theta(x_thisBranch).view(batch_size, self.inter_channels, -1)\n",
    "            phi_x = self.phi(x_otherBranch).view(batch_size, self.inter_channels, -1)\n",
    "            # theta_x = theta_x.permute(0, 2, 1)\n",
    "            phi_x = phi_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(phi_x, theta_x)\n",
    "\n",
    "        # elif self.mode == \"concatenate\":\n",
    "        else: #default as concatenate\n",
    "            theta_x = self.theta(x_thisBranch).view(batch_size, self.inter_channels, -1, 1)\n",
    "            phi_x = self.phi(x_otherBranch).view(batch_size, self.inter_channels, 1, -1)\n",
    "\n",
    "            h = theta_x.size(2)\n",
    "            w = phi_x.size(3)\n",
    "            theta_x = theta_x.repeat(1, 1, 1, w)\n",
    "            phi_x = phi_x.repeat(1, 1, h, 1)\n",
    "\n",
    "            concat = torch.cat([theta_x, phi_x], dim=1)\n",
    "            f = self.W_f(concat)\n",
    "            f = f.view(f.size(0), f.size(2), f.size(3))\n",
    "\n",
    "        if self.mode == \"gaussian\" or self.mode == \"embedded\":\n",
    "            f_div_C = F.softmax(f, dim=-1)\n",
    "        elif self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            N = f.size(-1)  # number of position in x\n",
    "            f_div_C = f / N\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "\n",
    "        # contiguous here just allocates contiguous chunk of memory\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x_thisBranch.size()[2:])\n",
    "\n",
    "        W_y = self.W_z(y)\n",
    "        # residual connection\n",
    "        z = W_y + x_thisBranch \n",
    "\n",
    "        return z\n",
    "\n",
    "Cross = NLBlockND_cross(32)\n",
    "input_size = (1, 32, 8, 32, 32)  # 示例输入大小\n",
    "\n",
    "# 创建一个示例的输入\n",
    "x1 = torch.randn(input_size)\n",
    "x2 = torch.randn(input_size)\n",
    "\n",
    "result1 = Cross(x1,x2)# 这里其实并没有改变输入的通道数\n",
    "result2 = Cross(x2,x1)# 这两个的输出是一样的\n",
    "\n",
    "print(result1.size())\n",
    "print(result2.size())\n",
    "# result = torch.cat((result1, result2), 1)\n",
    "# print(result.size())\n",
    "# print(result1)\n",
    "# print('============')\n",
    "# print(result2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 8, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "input_size = (1, 16, 16, 32, 32)  # 示例输入大小\n",
    "x1 = torch.randn(input_size)\n",
    "\n",
    "# pooltest = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2), padding=0)\n",
    "# torch.Size([1, 16, 16, 16, 16])\n",
    "# pooltest = nn.MaxPool3d(kernel_size=(1,2,2), stride=2, padding=0)\n",
    "# torch.Size([1, 16, 8, 16, 16])\n",
    "# pooltest = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "# torch.Size([1, 16, 8, 16, 16])\n",
    "result = pooltest(x1)\n",
    "print(result.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 64, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "input_size = (1, 16, 32, 128, 128)\n",
    "x1 = torch.randn(input_size)\n",
    "x2 = torch.randn(input_size)\n",
    "test = nn.Sequential(\n",
    "            # deconvolution:\n",
    "            # voxelmorph里面用的是上采样最近邻插值，我们用哪一个？\n",
    "            nn.ConvTranspose3d(in_channels=16, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=4, # kernel_size=2的话padding=0\n",
    "                               stride=2, # 在第二个里面是不是要给它放大四倍？因为前面是三个池化 不可以，因为要拼接\n",
    "                               padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "x1 = test(x1)\n",
    "print(x1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from deformable import *\n",
    "from SPT import *\n",
    "from Edge_ssim_loss import *\n",
    "\n",
    "fixed = np.load('/media/user_gou/Elements/Shi/Attention-Reg-main/cropeddata/01_01.npy')\n",
    "moving = np.load('/media/user_gou/Elements/Shi/Attention-Reg-main/cropeddata/02_01.npy')\n",
    "\n",
    "fixed = torch.tensor(fixed,dtype=torch.float64)\n",
    "moving = torch.tensor(moving,dtype=torch.float64)\n",
    "\n",
    "print(fixed.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelmorph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
